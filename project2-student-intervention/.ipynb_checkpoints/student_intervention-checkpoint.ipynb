{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Supervised Learning\n",
    "### Building a Student Intervention System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification vs Regression\n",
    "\n",
    "Your goal is to identify students who might need early intervention - which type of supervised machine learning problem is this, classification or regression? Why?\n",
    "\n",
    ">This is a classification problem, because we're trying to put students into one of 2 categories: those who need early intervention, and those who will perform adequately without it.  It's possible that this could be _phrased_ as a regression problem, if perhaps we were trying to predict students graduation GPA based on existing data, but as the problem stands we don't care about a particular point on a continuum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the Data\n",
    "\n",
    "Let's go ahead and read in the student dataset first.\n",
    "\n",
    "_To execute a code cell, click inside it and press **Shift+Enter**._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student data read successfully!\n"
     ]
    }
   ],
   "source": [
    "# Read student data\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print \"Student data read successfully!\"\n",
    "# Note: The last column 'passed' is the target/label, all other are feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you find out the following facts about the dataset?\n",
    "- Total number of students\n",
    "- Number of students who passed\n",
    "- Number of students who failed\n",
    "- Graduation rate of the class (%)\n",
    "- Number of features\n",
    "\n",
    "_Use the code block below to compute these values. Instructions/steps are marked using **TODO**s._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Number of features: 30\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "n_students = student_data['school'].count()\n",
    "n_features = student_data.dtypes.count() - 1 # because the last column is the target label\n",
    "n_passed = student_data[student_data['passed']=='yes']['passed'].count()\n",
    "n_failed = student_data[student_data['passed']=='no']['passed'].count()\n",
    "grad_rate = np.float32(n_passed)/np.float32(n_students) * 100\n",
    "\n",
    "print \"Total number of students: {}\".format(n_students)\n",
    "print \"Number of students who passed: {}\".format(n_passed)\n",
    "print \"Number of students who failed: {}\".format(n_failed)\n",
    "print \"Number of features: {}\".format(n_features)\n",
    "print \"Graduation rate of the class: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the Data\n",
    "In this section, we will prepare the data for modeling, training and testing.\n",
    "\n",
    "### Identify feature and target columns\n",
    "It is often the case that the data you obtain contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n",
    "\n",
    "Let's first separate our data into feature and target columns, and see if any features are non-numeric.<br/>\n",
    "**Note**: For this dataset, the last column (`'passed'`) is the target or label we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):-\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "Target column: passed\n",
      "\n",
      "Feature values:-\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(student_data.columns[:-1])  # all columns but last are features\n",
    "target_col = student_data.columns[-1]  # last column is the target/label\n",
    "print \"Feature column(s):-\\n{}\".format(feature_cols)\n",
    "print \"Target column: {}\".format(target_col)\n",
    "\n",
    "X_all = student_data[feature_cols]  # feature values for all students\n",
    "y_all = student_data[target_col]  # corresponding targets/labels\n",
    "print \"\\nFeature values:-\"\n",
    "print X_all.head()  # print the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess feature columns\n",
    "\n",
    "As you can see, there are several non-numeric columns that need to be converted! Many of them are simply `yes`/`no`, e.g. `internet`. These can be reasonably converted into `1`/`0` (binary) values.\n",
    "\n",
    "Other columns, like `Mjob` and `Fjob`, have more than two values, and are known as _categorical variables_. The recommended way to handle such a column is to create as many columns as possible values (e.g. `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc.), and assign a `1` to one of them and `0` to all others.\n",
    "\n",
    "These generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48):-\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "        # Note: This should change the data type for yes/no columns to int\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)  # e.g. 'school' => 'school_GP', 'school_MS'\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "\n",
    "    return outX\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets\n",
    "\n",
    "So far, we have converted all _categorical_ features into numeric values. In this next step, we split the data (both features and corresponding labels) into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 300 samples\n",
      "Test set: 95 samples\n"
     ]
    }
   ],
   "source": [
    "# First, decide how many training vs test samples you want\n",
    "num_all = student_data.shape[0]  # same as len(student_data)\n",
    "num_train = 300  # about 75% of the data\n",
    "num_test = num_all - num_train\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "splitter = StratifiedShuffleSplit(y_all, 1, test_size=num_test, random_state=29)\n",
    "\n",
    "for train_index, test_index in splitter:\n",
    "  X_train = X_all.iloc[train_index]\n",
    "  y_train = y_all.iloc[train_index]\n",
    "  X_test = X_all.iloc[test_index]\n",
    "  y_test = y_all.iloc[test_index]\n",
    "\n",
    "print \"Training set: {} samples\".format(X_train.shape[0])\n",
    "print \"Test set: {} samples\".format(X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluating Models\n",
    "Choose 3 supervised learning models that are available in scikit-learn, and appropriate for this problem. For each model:\n",
    "\n",
    "- What is the theoretical O(n) time & space complexity in terms of input size?\n",
    "- What are the general applications of this model? What are its strengths and weaknesses?\n",
    "- Given what you know about the data so far, why did you choose this model to apply?\n",
    "- Fit this model to the training data, try to predict labels (for both training and test sets), and measure the F<sub>1</sub> score. Repeat this process with different training set sizes (100, 200, 300), keeping test set constant.\n",
    "\n",
    "Produce a table showing training time, prediction time, F<sub>1</sub> score on training set and F<sub>1</sub> score on test set, for each training set size.\n",
    "\n",
    "Note: You need to produce 3 such tables - one for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.005\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "import time\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print \"Training {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print \"Done!\\nTraining time (secs): {:.3f}\".format(end - start)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# Fit model to training data\n",
    "train_classifier(clf, X_train, y_train)  # note: using entire training set here\n",
    "print clf  # you can inspect the learned model by printing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.006\n",
      "F1 score for training set: 0.856492027335\n"
     ]
    }
   ],
   "source": [
    "# Predict on training set and compute F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print \"Predicting labels using {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print \"Done!\\nPrediction time (secs): {:.3f}\".format(end - start)\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "train_f1_score = predict_labels(clf, X_train, y_train)\n",
    "print \"F1 score for training set: {}\".format(train_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.742857142857\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "print \"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 50\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for training set: 0.9\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.805369127517\n",
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.000\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for training set: 0.853333333333\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.772413793103\n",
      "------------------------------------------\n",
      "Training set size: 150\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.000\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for training set: 0.874418604651\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.769230769231\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.000\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for training set: 0.88\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.757142857143\n",
      "------------------------------------------\n",
      "Training set size: 250\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.004\n",
      "F1 score for training set: 0.854794520548\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.765957446809\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training KNeighborsClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.004\n",
      "F1 score for training set: 0.856492027335\n",
      "Predicting labels using KNeighborsClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.742857142857\n"
     ]
    }
   ],
   "source": [
    "# Train and predict using different training set sizes\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    print \"------------------------------------------\"\n",
    "    print \"Training set size: {}\".format(len(X_train))\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    print \"F1 score for training set: {}\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test))\n",
    "\n",
    "train_predict(clf, X_train[0:50], y_train[0:50], X_test, y_test)\n",
    "train_predict(clf, X_train[0:100], y_train[0:100], X_test, y_test)\n",
    "train_predict(clf, X_train[0:150], y_train[0:150], X_test, y_test)\n",
    "train_predict(clf, X_train[0:200], y_train[0:200], X_test, y_test)\n",
    "train_predict(clf, X_train[0:250], y_train[0:250], X_test, y_test)\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "# Note: Keep the test set constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.004\n",
      "------------------------------------------\n",
      "Training set size: 50\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for training set: 1.0\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.739130434783\n",
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 1.0\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.728682170543\n",
      "------------------------------------------\n",
      "Training set size: 150\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 1.0\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.702290076336\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 1.0\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.754098360656\n",
      "------------------------------------------\n",
      "Training set size: 250\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 1.0\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.725806451613\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.002\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 1.0\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.761194029851\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "d_clf = DecisionTreeClassifier(random_state=29)\n",
    "train_classifier(d_clf, X_train, y_train)\n",
    "\n",
    "train_predict(d_clf, X_train[0:50], y_train[0:50], X_test, y_test)\n",
    "train_predict(d_clf, X_train[0:100], y_train[0:100], X_test, y_test)\n",
    "train_predict(d_clf, X_train[0:150], y_train[0:150], X_test, y_test)\n",
    "train_predict(d_clf, X_train[0:200], y_train[0:200], X_test, y_test)\n",
    "train_predict(d_clf, X_train[0:250], y_train[0:250], X_test, y_test)\n",
    "train_predict(d_clf, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GaussianNB...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "------------------------------------------\n",
      "Training set size: 50\n",
      "Training GaussianNB...\n",
      "Done!\n",
      "Training time (secs): 0.000\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 0.62962962963\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.325581395349\n",
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training GaussianNB...\n",
      "Done!\n",
      "Training time (secs): 0.000\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 0.436781609195\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.2\n",
      "------------------------------------------\n",
      "Training set size: 150\n",
      "Training GaussianNB...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 0.415384615385\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.302325581395\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training GaussianNB...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 0.807272727273\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.781954887218\n",
      "------------------------------------------\n",
      "Training set size: 250\n",
      "Training GaussianNB...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 0.810495626822\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.746031746032\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training GaussianNB...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 0.799043062201\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.781954887218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_clf = GaussianNB()\n",
    "train_classifier(nb_clf, X_train, y_train)\n",
    "\n",
    "train_predict(nb_clf, X_train[0:50], y_train[0:50], X_test, y_test)\n",
    "train_predict(nb_clf, X_train[0:100], y_train[0:100], X_test, y_test)\n",
    "train_predict(nb_clf, X_train[0:150], y_train[0:150], X_test, y_test)\n",
    "train_predict(nb_clf, X_train[0:200], y_train[0:200], X_test, y_test)\n",
    "train_predict(nb_clf, X_train[0:250], y_train[0:250], X_test, y_test)\n",
    "train_predict(nb_clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.012\n",
      "------------------------------------------\n",
      "Training set size: 50\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for training set: 0.90243902439\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.812903225806\n",
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for training set: 0.888888888889\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.807692307692\n",
      "------------------------------------------\n",
      "Training set size: 150\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.002\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for training set: 0.891891891892\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.8\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.003\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for training set: 0.880258899676\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.797385620915\n",
      "------------------------------------------\n",
      "Training set size: 250\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.004\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.003\n",
      "F1 score for training set: 0.870466321244\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.002\n",
      "F1 score for test set: 0.797385620915\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.008\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.004\n",
      "F1 score for training set: 0.868421052632\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.797385620915\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_clf = svm.SVC(random_state=29)\n",
    "train_classifier(svm_clf, X_train, y_train)\n",
    "\n",
    "train_predict(svm_clf, X_train[0:50], y_train[0:50], X_test, y_test)\n",
    "train_predict(svm_clf, X_train[0:100], y_train[0:100], X_test, y_test)\n",
    "train_predict(svm_clf, X_train[0:150], y_train[0:150], X_test, y_test)\n",
    "train_predict(svm_clf, X_train[0:200], y_train[0:200], X_test, y_test)\n",
    "train_predict(svm_clf, X_train[0:250], y_train[0:250], X_test, y_test)\n",
    "train_predict(svm_clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors\n",
    "\n",
    "##### Complexity\n",
    "\n",
    "Space will be consumed faster than runtime for training.  KNN defers computation to when you try to use it for prediction, so it's training time is O(1).  Prediction runtime, however, will go up as we add data. KNN needs to find the K closest points to a new data point, which means examining every point in the dataset (barring some clever sectioning of the data).  If you add 3 more data points to the set, prediction will have to calculate 3 more distances.  This seems to be O(n).\n",
    "\n",
    "Space should be O(n) as for each additional data point, we consume 1 unit of additional space to store it for use during classification of novel data.\n",
    "\n",
    "\n",
    "##### General Application\n",
    "\n",
    "KNN has the advantage of being a fairly simple algorithm to intuit the behavior of.  It just finds the K most similar points to a new data point, and uses a vote betwen them to decide how to classify it.  This works well for low dimensionality space that is relatively well clustered.  One downside of the algorithm is that for clusters that have complex decision boundaries, the closest points might not be a good measure of where the new point should fit.  Another drawback is that the prediction function is computationally intensive for large data sets, so adding more data will help the accuracy, but hinder the runtime for each prediction.\n",
    "\n",
    "##### Inclusion in Experiment\n",
    "\n",
    "Nearest Neighbors seems to have some intuitively correct application to this problem. If a student's habits, health, and employment are all very close to points for other passing students, it seems likely that student will be more likely to pass.\n",
    "\n",
    "##### Results\n",
    "\n",
    "| Training Set Size | Training Time | Prediction Time | F1 Score (train) | F1 Score (test) |\n",
    "| ----------------- |:-------------:| ---------------:|  ---------------:|  --------------:|\n",
    "| 50                | 0.001         | 0.001           | 0.9              | 0.805369127517  |\n",
    "| 100               | 0.000         | 0.001           | 0.853333333333   | 0.769230769231  |\n",
    "| 150               | 0.000         | 0.002           | 0.874418604651   | 0.794520547945  |\n",
    "| 200               | 0.001         | 0.002           | 0.88             | 0.757142857143  |\n",
    "| 250               | 0.001         | 0.004           | 0.854794520548   | 0.765957446809  |\n",
    "| 300               | 0.001         | 0.004           | 0.856492027335   | 0.74285714285   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "##### Complexity\n",
    "\n",
    "As the number of points in a dataset goes up, it will be possible to continue to subdivide them further, so both training and prediction runtime will rise.  However, adding one more point doesn't add one more decision.  O(logN) should better describe how adding additional data provides more decision opportunities.  Space too grows (more decisions to keep track of)\n",
    "\n",
    "Space should be O(n) as for each additional data point, we consume 1 unit of additional space to store it for use during classification of novel data.\n",
    "\n",
    "\n",
    "##### General Application\n",
    "\n",
    "I like decision trees because the resulting algorithm is inspectable.  I might not be able to intuit why a particular feature is resulting in information gain for a particular decision, but I can confirm for myself in the data that it is the case.\n",
    "\n",
    "As a downside, decision trees overfit fairly easily, especially if allowed to continue to create additional decisions deep in the tree (continuing to split leafs that already only have a handful of points in them).\n",
    "\n",
    "##### Inclusion in Experiment\n",
    "\n",
    "This is another algorithm I included for intuitive reasons, because if I were to want to classify this data myself without a program, it's analogous to how I would want to go about it.  I'd want to look at a data feature I suspected of being relevant, and see how splitting the data along those lines looked in terms of clustering, and then would look for additional features to effectively seperate the remainder of the data points.\n",
    "\n",
    "##### Results\n",
    "\n",
    "| Training Set Size | Training Time | Prediction Time | F1 Score (train) | F1 Score (test) |\n",
    "| ----------------- |:-------------:| ---------------:|  ---------------:|  --------------:|\n",
    "| 50                | 0.001         | 0.001           | 1.0              | 0.739130434783  |\n",
    "| 100               | 0.001         | 0.000           | 1.0              | 0.728682170543  |\n",
    "| 150               | 0.001         | 0.000           | 1.0              | 0.702290076336  |\n",
    "| 200               | 0.001         | 0.000           | 1.0              | 0.754098360656  |\n",
    "| 250               | 0.001         | 0.000           | 1.0              | 0.725806451613  |\n",
    "| 300               | 0.002         | 0.000           | 1.0              | 0.761194029851  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "##### Complexity\n",
    "\n",
    "Because you usually have more data records than features, and because bayes is calculating a one-dimensional distribution per feature, it's actually more expensive in terms of runtime to add another feature column than to add more data rows.  Runtime should scale at O(n) for training, each additional data point is one more item to include in each feature's distribution calculation.\n",
    "\n",
    "space should be O(1), since the distributions don't take on additional size with each data point, just different values.  For the same reason, prediction runtime should be O(1) (no matter how many data points you used to create each feature's distribution, you're still comparing each novel data point feature to eah distribution once.\n",
    "\n",
    "\n",
    "##### General Application\n",
    "\n",
    "Bayes classifiers consider each feature independent from each other, which makes it resiliant to high-dimensional spaces, and therefore particularly good for datasets made predominantly from text.  Things like spam identification and text authorship identification can be done surprisingly effectively with it.\n",
    "\n",
    "##### Inclusion in Experiment\n",
    "\n",
    "There are a decent number of features for each student in this data set, so I wanted to include a Bayesian algorithm on the off chance that it performed particularly well (it didn't).\n",
    "\n",
    "| Training Set Size | Training Time | Prediction Time | F1 Score (train) | F1 Score (test) |\n",
    "| ----------------- |:-------------:| ---------------:|  ---------------:|  --------------:|\n",
    "| 50                | 0.000         | 0.000           | 0.62962962963    | 0.325581395349  |\n",
    "| 100               | 0.000         | 0.000           | 0.436781609195   | 0.2             |\n",
    "| 150               | 0.001         | 0.000           | 0.415384615385   | 0.302325581395  |\n",
    "| 200               | 0.001         | 0.000           | 0.807272727273   | 0.781954887218  |\n",
    "| 250               | 0.001         | 0.000           | 0.810495626822   | 0.746031746032  |\n",
    "| 300               | 0.001         | 0.000           | 0.799043062201   | 0.781954887218  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "\n",
    "##### Complexity\n",
    "\n",
    "Runtime in training can be pretty variable depending on which kernal you use, but in any case optimizing for margin requires examining each point more than once as different boundaries are tried.  At least O(n\\*log(n)), possibly O(n^2).\n",
    "\n",
    "Prediction time is also comparatively slow, at least in the results table we have here.  Prediction appears to be roughly linear with respect to amount of training data [ O(n) ]\n",
    "\n",
    "##### General Application\n",
    "\n",
    "Support vector machines try to find a decision boundary between labels that is as far away as possible from the points closest to the boundary, maximizing the margin for unknown data points.  If allowed to make too complex a decision boundary, they can be prone to overfitting, but are generally a good candidate for using on data sets that have a high number of features.  There are many examples of them being used to classify visual data surprisingly well.\n",
    "\n",
    "##### Inclusion in Experiment\n",
    "\n",
    "SVMs are one of the most widely applied algorithms in the subset of research I've read about, so since the cost of adding one more classifier to the experiment was low it seemed prudent to include.\n",
    "\n",
    "\n",
    "| Training Set Size | Training Time | Prediction Time | F1 Score (train) | F1 Score (test) |\n",
    "| ----------------- |:-------------:| ---------------:|  ---------------:|  --------------:|\n",
    "| 50                | 0.001         | 0.001           | 0.90243902439    | 0.812903225806  |\n",
    "| 100               | 0.001         | 0.001           | 0.888888888889   | 0.807692307692  |\n",
    "| 150               | 0.002         | 0.001           | 0.891891891892   | 0.8             |\n",
    "| 200               | 0.003         | 0.002           | 0.880258899676   | 0.797385620915  |\n",
    "| 250               | 0.004         | 0.003           | 0.870466321244   | 0.797385620915  |\n",
    "| 300               | 0.008         | 0.004           | 0.868421052632   | 0.797385620915  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Choosing the Best Model\n",
    "\n",
    "- Based on the experiments you performed earlier, in 1-2 paragraphs explain to the board of supervisors what single model you chose as the best model. Which model is generally the most appropriate based on the available data, limited resources, cost, and performance?\n",
    "\n",
    "> In the comparison process I evaluated 4 common classifier algorithms (KNN, Decision Tree, Naive Bayes, and SVM) over the sample dataset.  Of the four, one stood out as a relatively inferior fit; the KNN algorithm, even when provided with the maximum training dataset, still couldn't even produce an F1 score of 0.75 while the other 3 algorithms were each up to an FT of greater than 0.75 when provided with the full training data.  Of the remaining 3, Decision Trees are less accurate than Naive Bayes, which are less accurate than SVM (which provided the highest accuracy of all, F1 of 0.79).\n",
    "\n",
    "> Accuracy is not the only concern at play.  Based on Board's expressed preference for a cost-concious model, I think that Naive Bayes would provide a marginally better long term cost if the usage pattern is balanced the way I suspect (infrequent infusions of additional training data, frequent prediction requests).  In both training time and prediction time, Naive Bayes runs faster (and therefore cheaper).  However, if the training dataset is representative of the order of magnitude of data we're going to be running this system with, it may not matter very much.  At the observed growth rate of training time with respect to input data size (doubling about every hundered records added), you'd be up to 1,000 records before it took even 1 second to train the SVM.  If it's going to be much larger, though, and if the growth rate holds, then at 2000 data points it would be taking a little less than 20 minutes, and at 2500 it would be taking hours. So if the data gets really big, naive bayes may provide a better tradeoff.  At this size of dataset though, the SVM _is_ the most accurate of all, and it's still feasible to run fairly quickly.\n",
    "\n",
    "- In 1-2 paragraphs explain to the board of supervisors in layman's terms how the final model chosen is supposed to work (for example if you chose a Decision Tree or Support Vector Machine, how does it make a prediction).\n",
    "\n",
    "> Any description of a technical topic to a non-technical audience is likely to be fraught with poor assumptions about the transparency of given jargon and the struggle to find the appropriate level of abstraction to gain the necessary intuition for a given solution.  With this in mind I'll try to write simply to minimize poor assumptions on my part about any particular piece of foundational knowledge: The model selected from the experiment so far is known as a Support Vector Machine Classifier.  The name does accurately represent some of the underlying mathematical concepts at play, but rather than dive too deeply into the derivation of the name instead let's focus on how it works.\n",
    "\n",
    "> SVMs can be thought of as an attempt to plot all the data we have on a grid, and draw the line between the categories that is as close as possible to being evenly drawn between them (maximizing the margin).  Imagine taking each student and assigning them a shirt color (red if they failed, green if they passed) and having them all stand on a football field at points are calculated as a function of all of the things we know about them (so the same employment, habits, demographic would place a student at the same point on the field).  Now we start trying to set out traffic cones on the field to divide the students in red shirts from the students in green shirts, trying to keep the cones as far away from any individual student as possible.  Now if we took any new student, not knowing yet whether they would pass or fail, we could still find the right spot on the field for them by asking about their habits, demographic, and employment.  Then we just look at where the new student is standing, whether that point is on a red side of the divison, or the green side.  That's how we make our prediction.  It's a bit of a funny picture to imagine, but it's a decent thought experiment to help set out how SVMs work in a familiar setting.\n",
    "\n",
    "- Fine-tune the model. Use Gridsearch with at least one important parameter tuned and with at least 3 settings. Use the entire training set for this.\n",
    "\n",
    "- What is the model's final F<sub>1</sub> score?\n",
    "\n",
    "> 0.810126582278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS SET\n",
      "{'kernel': 'rbf', 'C': 0.5, 'gamma': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "params_map = [{\n",
    "         'C': [0.5, 1.0, 2.0, 5.0, 10.0, 100.0],\n",
    "         'kernel': ['rbf', 'linear'],\n",
    "         'gamma': ['auto',1.0, 5.0, 10.0]\n",
    "        }]\n",
    "\n",
    "def f1_score_on_test(estimator, x, y):\n",
    "  y_pred = estimator.predict(X_test)\n",
    "  return f1_score(y_test.values, y_pred, pos_label='yes')\n",
    "  \n",
    "\n",
    "gsv = GridSearchCV(svm.SVC(random_state=29), params_map, scoring=f1_score_on_test)\n",
    "gsv.fit(X_train, y_train)\n",
    "print(\"BEST PARAMS SET\")\n",
    "print(gsv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.006\n",
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.006\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.004\n",
      "F1 score for training set: 0.832298136646\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.001\n",
      "F1 score for test set: 0.810126582278\n"
     ]
    }
   ],
   "source": [
    "svm_optimized_clf = svm.SVC(random_state=29, kernel='rbf',C=0.5, gamma='auto')\n",
    "\n",
    "train_classifier(svm_optimized_clf, X_train, y_train)\n",
    "\n",
    "train_predict(svm_optimized_clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
